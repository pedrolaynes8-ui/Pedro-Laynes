{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HR7vsaDEQ8XmQdb_bTh2xqHa_fOuQ0ZE",
      "authorship_tag": "ABX9TyOw3niFY2Rd6A9XVkgE4Bfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pedro-Laynes/Proyecto-de-tesis-Pedro/blob/main/Proyecto_Anisakidos_COX2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlhuzySNhOua",
        "outputId": "50769641-b8b1-47f7-fe4e-07a249979e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Estructura de proyecto creada en Google Drive:\n",
            " - data/raw\n",
            " - data/processed\n",
            " - data/metadata\n",
            " - scripts\n",
            " - results/blast\n",
            " - results/alineamientos\n",
            " - results/arboles\n",
            " - results/figuras\n",
            " - docs\n",
            " - notebooks\n",
            "\n",
            "README.md creado.\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# 1. MONTTAJE GOOGLE DRIVE\n",
        "# ======================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta base del proyecto en Drive\n",
        "project_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2\"\n",
        "\n",
        "import os\n",
        "\n",
        "# ======================================\n",
        "# 2. CREACI√ìN DE ESTRUCTURA DE CARPETAS\n",
        "# ======================================\n",
        "\n",
        "folders = [\n",
        "    \"data/raw\",\n",
        "    \"data/processed\",\n",
        "    \"data/metadata\",\n",
        "    \"scripts\",\n",
        "    \"results/blast\",\n",
        "    \"results/alineamientos\",\n",
        "    \"results/arboles\",\n",
        "    \"results/figuras\",\n",
        "    \"docs\",\n",
        "    \"notebooks\"\n",
        "]\n",
        "\n",
        "for f in folders:\n",
        "    path = os.path.join(project_path, f)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "print(\"Estructura de proyecto creada en Google Drive:\")\n",
        "for f in folders:\n",
        "    print(\" -\", f)\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# 3. CREAR README.md B√ÅSICO\n",
        "# ======================================\n",
        "\n",
        "readme_text = \"\"\"\n",
        "# Caracterizaci√≥n molecular de larvas de anis√°kidos (Nematoda: Anisakidae) en peces comerciales de Loreto - Per√∫ mediante an√°lisis del gen mitocondrial COX2\n",
        "\n",
        "## üìå Descripci√≥n general del proyecto\n",
        "Este proyecto tiene como finalidad identificar molecularmente larvas de nem√°todos de la familia Anisakidae presentes en peces de importancia comercial de la regi√≥n Loreto (Per√∫), mediante el an√°lisis del gen mitocondrial COX2, determinaci√≥n de secuencias consenso, b√∫squeda de similitud en bases de datos p√∫blicas y reconstrucci√≥n filogen√©tica (NJ, ML e inferencia bayesiana).\n",
        "\n",
        "El estudio forma parte de un trabajo de caracterizaci√≥n parasitol√≥gica y molecular de par√°sitos zoon√≥ticos asociados a peces amaz√≥nicos.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Hip√≥tesis\n",
        "**H1:** El uso de herramientas moleculares, como la secuenciaci√≥n del gen mitocondrial COX2, permite identificar e inferir la diversidad gen√©tica de nem√°todos de la familia Anisakidae presentes en peces de importancia comercial en la regi√≥n de Loreto.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objetivo general\n",
        "**Caracterizar molecularmente larvas de nem√°todos de la familia Anisakidae presentes en peces de importancia comercial de Loreto, Per√∫, mediante secuenciaci√≥n del gen mitocondrial COX2 y an√°lisis filogen√©ticos.**\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objetivos espec√≠ficos\n",
        "1. Identificar los morfotipos larvales de nem√°todos anis√°kidos mediante an√°lisis morfol√≥gico y morfom√©trico.\n",
        "2. Estandarizar y optimizar un protocolo molecular para extracci√≥n, amplificaci√≥n y secuenciaci√≥n del gen COX2.\n",
        "3. Determinar la identidad taxon√≥mica de los nem√°todos mediante an√°lisis filogen√©tico y comparaci√≥n con secuencias de referencia.\n",
        "4. Evaluar la diversidad gen√©tica intra e interespec√≠fica mediante an√°lisis de haplotipos y par√°metros poblacionales.\n",
        "\n",
        "---\n",
        "\n",
        "## üêü Tama√±o de muestra\n",
        "- **100 peces** obtenidos de mercados y puntos de venta de Iquitos (Loreto).\n",
        "- Estos peces pertenecen a **20 especies comerciales diferentes**.\n",
        "- Se esperan obtener **~50 nem√°todos por especie**.\n",
        "- Se registran diferentes morfotipos para an√°lisis morfol√≥gico preliminar.\n",
        "\n",
        "Cuatro nem√°todos (c√≥digos 453, 454, 455, 456), identificados morfol√≥gicamente como larvas del g√©nero **Contracaecum**, fueron seleccionados para an√°lisis molecular y secuenciaci√≥n Sanger del gen COX2.\n",
        "\n",
        "---\n",
        "\n",
        "## üß¨ Dataset incluido\n",
        "En este repositorio se incluyen **8 secuencias Sanger (.ab1):**\n",
        "- 453_F.ab1 / 453_R.ab1\n",
        "- 454_F.ab1 / 454_R.ab1\n",
        "- 455_F.ab1 / 455_R.ab1\n",
        "- 456_F.ab1 / 456_R.ab1\n",
        "\n",
        "Estas se encuentran en `data/raw/`.\n",
        "\n",
        "---\n",
        "\n",
        "## üß∞ Scripts incluidos (avance ~40%)\n",
        "Los scripts se encuentran en la carpeta `scripts/`:\n",
        "\n",
        "1. `01_leer_ab1_y_generar_consenso.R`\n",
        "   - Lectura de archivos AB1\n",
        "   - Obtenci√≥n de secuencias forward y reverse\n",
        "   - Generaci√≥n de secuencia consenso\n",
        "\n",
        "2. `02_limpieza_y_trimming.R`\n",
        "   - Curado de secuencias consenso\n",
        "   - Recorte de regiones de baja calidad\n",
        "\n",
        "3. `03_blast_automatico.R`\n",
        "   - BLAST contra NCBI desde R / bio3d o rentrez\n",
        "\n",
        "4. `04_alineamiento_global_MAFFT.R`\n",
        "   - Alineamiento con secuencias de referencia\n",
        "\n",
        "5. `05_arbol_NJ_ML.R`\n",
        "   - Reconstrucci√≥n filogen√©tica (NJ, ML)\n",
        "   - Bootstrap\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(project_path, \"README.md\"), \"w\") as f:\n",
        "    f.write(readme_text)\n",
        "\n",
        "print(\"\\nREADME.md creado.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL3_7-4DnE11",
        "outputId": "d57cf728-8dcb-4a2f-8ac7-db97cefe51da"
      },
      "source": [
        "import os\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.Align import PairwiseAligner\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "\n",
        "# ===========================================================\n",
        "# 0. INSTALAR LIBRER√çAS\n",
        "# ===========================================================\n",
        "!pip install biopython\n",
        "\n",
        "# ===========================================================\n",
        "# 1. MONTAR GOOGLE DRIVE\n",
        "# ===========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# project_path est√° definido en una celda anterior y disponible en el entorno.\n",
        "# project_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2\"\n",
        "\n",
        "# Rutas a las carpetas de raw y processed\n",
        "raw_data_path = os.path.join(project_path, \"data\", \"raw\")\n",
        "processed_data_path = os.path.join(project_path, \"data\", \"processed\")\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# 2. FUNCI√ìN: LEER ARCHIVO AB1\n",
        "# ===========================================================\n",
        "def leer_ab1(ruta):\n",
        "    registro = SeqIO.read(ruta, \"abi\")\n",
        "    return registro.seq\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# 3. FUNCI√ìN: GENERAR CONSENSO F + R\n",
        "# ===========================================================\n",
        "def generar_consenso(seqF, seqR):\n",
        "    aligner = PairwiseAligner()\n",
        "    aligner.mode = \"global\"\n",
        "\n",
        "    # Reverse complement de la secuencia reversa\n",
        "    seqR_rc = seqR.reverse_complement()\n",
        "\n",
        "    # Obtener el primer alineamiento de la lista (que es un objeto Alignment)\n",
        "    aln = aligner.align(seqF, seqR_rc)[0]\n",
        "\n",
        "    # Acceder a las secuencias alineadas usando los atributos .target y .query\n",
        "    aligned_seqF = aln.target\n",
        "    aligned_seqR = aln.query\n",
        "\n",
        "    cons = []\n",
        "    for bF, bR in zip(aligned_seqF, aligned_seqR):\n",
        "        if bF == bR:\n",
        "            cons.append(bF)\n",
        "        else:\n",
        "            if bF == \"-\":\n",
        "                cons.append(bR)\n",
        "            elif bR == \"-\":\n",
        "                cons.append(bF)\n",
        "            else:\n",
        "                cons.append(\"N\")\n",
        "    return Seq(\"\".join(cons))\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# 4. FUNCI√ìN: LIMPIEZA SIMPLE\n",
        "# ===========================================================\n",
        "def limpiar_seq(seq):\n",
        "    seq_str = str(seq)\n",
        "    seq_str = seq_str.strip(\"N\")\n",
        "    return Seq(seq_str)\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# 5. PROCESAR TUS MUESTRAS 453‚Äì456\n",
        "# ===========================================================\n",
        "\n",
        "muestras = [\"453\", \"454\", \"455\", \"456\"]\n",
        "\n",
        "for code in muestras:\n",
        "\n",
        "    print(f\"\\nProcesando muestra {code} ...\")\n",
        "\n",
        "    # Nombres reales de tus archivos\n",
        "    fwd = os.path.join(raw_data_path, f\"{code}_Cox2-211F.ab1\")\n",
        "    rev = os.path.join(raw_data_path, f\"{code}_Cox2-211R.ab1\")\n",
        "\n",
        "    seqF = leer_ab1(fwd)\n",
        "    seqR = leer_ab1(rev)\n",
        "\n",
        "    consenso = generar_consenso(seqF, seqR)\n",
        "    limpio = limpiar_seq(consenso)\n",
        "\n",
        "    # Guardar FASTA limpio\n",
        "    out_fasta = os.path.join(processed_data_path, f\"{code}_COX2_clean.fasta\")\n",
        "    SeqIO.write(\n",
        "        SeqRecord(limpio, id=code+\"_clean\", description=\"COX2 consensus\"),\n",
        "        out_fasta,\n",
        "        \"fasta\"\n",
        "    )\n",
        "\n",
        "    print(f\"\\u2714 Exportado: {out_fasta}\")\n",
        "\n",
        "print(\"\\n\\u2714 PROCESAMIENTO COMPLETO DE TODAS LAS MUESTRAS\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.77)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Procesando muestra 453 ...\n",
            "‚úî Exportado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/453_COX2_clean.fasta\n",
            "\n",
            "Procesando muestra 454 ...\n",
            "‚úî Exportado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/454_COX2_clean.fasta\n",
            "\n",
            "Procesando muestra 455 ...\n",
            "‚úî Exportado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/455_COX2_clean.fasta\n",
            "\n",
            "Procesando muestra 456 ...\n",
            "‚úî Exportado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/456_COX2_clean.fasta\n",
            "\n",
            "‚úî PROCESAMIENTO COMPLETO DE TODAS LAS MUESTRAS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/README.md\"\n",
        "\n",
        "contenido = \"\"\"\n",
        "# Caracterizaci√≥n molecular de larvas de anis√°kidos (Nematoda: Anisakidae) en peces comerciales de Loreto, Per√∫ mediante el an√°lisis del gen mitocondrial COX2\n",
        "\n",
        "## üìå Descripci√≥n general del proyecto\n",
        "Este repositorio contiene el flujo bioinform√°tico completo desarrollado para la **identificaci√≥n molecular y an√°lisis filogen√©tico** de larvas de nem√°todos de la familia *Anisakidae* obtenidas de peces comerciales de la regi√≥n Loreto (Per√∫).\n",
        "El an√°lisis se basa en la secuenciaci√≥n Sanger del **gen mitocondrial COX2**, ampliamente utilizado para delimitaci√≥n de especies dentro de este grupo.\n",
        "\n",
        "---\n",
        "\n",
        "## üß¨ Hip√≥tesis\n",
        "**H1:** El uso de herramientas moleculares, como la secuenciaci√≥n del gen mitocondrial COX2, permite identificar e inferir la diversidad gen√©tica de nem√°todos de la familia *Anisakidae* presentes en peces de importancia comercial en la regi√≥n de Loreto.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objetivo general\n",
        "Caracterizar molecularmente larvas de nem√°todos de la familia Anisakidae presentes en peces comerciales de Loreto mediante la secuenciaci√≥n del gen mitocondrial COX2 y el an√°lisis filogen√©tico comparativo con especies de referencia.\n",
        "\n",
        "## üîç Objetivos espec√≠ficos\n",
        "- Identificar los morfotipos larvales de Anisakidae mediante an√°lisis morfol√≥gico y morfom√©trico.\n",
        "- Estandarizar y optimizar el procesamiento molecular del gen COX2 (extracci√≥n, amplificaci√≥n y secuenciaci√≥n).\n",
        "- Determinar la identidad taxon√≥mica de las muestras mediante an√°lisis filogen√©tico con secuencias de referencia del NCBI.\n",
        "- Evaluar la diversidad gen√©tica intra e interespec√≠fica mediante an√°lisis de haplotipos y par√°metros poblacionales.\n",
        "\n",
        "---\n",
        "\n",
        "## üêü Material biol√≥gico\n",
        "- **100 peces** adquiridos en Iquitos (Loreto).\n",
        "- **20 especies diferentes** de peces comerciales.\n",
        "- De cada especie se analizaron ~50 nem√°todos, previo an√°lisis morfol√≥gico.\n",
        "- Para el an√°lisis molecular, se seleccionaron 4 larvas con morfotipo compatible con *Contracaecum*:\n",
        "\n",
        "Los c√≥digos de archivos son los siguientes:\n",
        "\n",
        "453_Cox2-211F.ab1\n",
        "453_Cox2-211R.ab1\n",
        "454_Cox2-211F.ab1\n",
        "454_Cox2-211R.ab1\n",
        "455_Cox2-211F.ab1\n",
        "455_Cox2-211R.ab1\n",
        "456_Cox2-211F.ab1\n",
        "456_Cox2-211R.ab1\n",
        "\n",
        "Cada una con secuencias Sanger Forward y Reverse (.ab1).\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Datos generados\n",
        "Las secuencias fueron procesadas para obtener FASTA limpios:\n",
        "\n",
        "data/processed/453_COX2_clean.fasta\n",
        "data/processed/454_COX2_clean.fasta\n",
        "data/processed/455_COX2_clean.fasta\n",
        "data/processed/456_COX2_clean.fasta\n",
        "\n",
        "\n",
        "Estas secuencias est√°n listas para an√°lisis filogen√©tico.\n",
        "\n",
        "---\n",
        "\n",
        "## üñ•Ô∏è Pipeline bioinform√°tico del proyecto\n",
        "\n",
        "1. **Lectura de archivos AB1** (Forward y Reverse)\n",
        "2. **Generaci√≥n de reverse complement**\n",
        "3. **Alineamiento F + R (pairwise)**\n",
        "4. **Construcci√≥n de secuencia consenso**\n",
        "5. **Trimming y limpieza de Ns**\n",
        "6. **Exportaci√≥n en formato FASTA**\n",
        "7. **BLAST en NCBI para identificaci√≥n preliminar**\n",
        "8. **Alineamiento m√∫ltiple (MAFFT / MUSCLE)**\n",
        "9. **Filogenia (NJ, ML, Bayesian)**\n",
        "10. **C√°lculo de diversidad gen√©tica (opcional)**\n",
        "\n",
        "Los scripts correspondientes se encuentran en la carpeta `/scripts`.\n",
        "\n",
        "---\n",
        "\n",
        "## üóÇÔ∏è Estructura del repositorio\n",
        "\n",
        "Proyecto-Anisakidos-COX2/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ data/\n",
        "‚îÇ ‚îú‚îÄ‚îÄ raw/ # Archivos .ab1 originales\n",
        "‚îÇ ‚îú‚îÄ‚îÄ processed/ # FASTA limpios y consensos\n",
        "‚îÇ ‚îî‚îÄ‚îÄ metadata/ # Info de muestras (por completar)\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ scripts/ # An√°lisis bioinform√°ticos (Python/R)\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ results/\n",
        "‚îÇ ‚îú‚îÄ‚îÄ blast/\n",
        "‚îÇ ‚îú‚îÄ‚îÄ alineamientos/\n",
        "‚îÇ ‚îú‚îÄ‚îÄ arboles/\n",
        "‚îÇ ‚îî‚îÄ‚îÄ figuras/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ docs/ # Informe en RMarkdown, metodolog√≠a y reportes\n",
        "‚îÇ\n",
        "‚îî‚îÄ‚îÄ notebooks/ # Notebooks de Google Colab del proyecto\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## üß∞ Tecnolog√≠as utilizadas\n",
        "\n",
        "- **Google Colab**\n",
        "- **Python + Biopython**\n",
        "- **R (ape, phangorn, ggtree)**\n",
        "- **MAFFT / MUSCLE**\n",
        "- **NCBI BLASTn**\n",
        "- **GitHub para control de versiones**\n",
        "\n",
        "---\n",
        "\n",
        "## üë®‚Äçüî¨ Autora\n",
        "Estudiante: *[Tu nombre]*\n",
        "Proyecto acad√©mico ‚Äì Universidad *[Tu universidad]*\n",
        "Curso: Bioinform√°tica\n",
        "\n",
        "---\n",
        "\n",
        "## üìé Contacto\n",
        "Si alguien desea reutilizar o revisar este pipeline, puede contactar v√≠a correo acad√©mico.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(project_path, \"w\") as f:\n",
        "    f.write(contenido)\n",
        "\n",
        "print(\"README.md actualizado correctamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VGFuDQpuzJ6",
        "outputId": "4acc31c8-8712-41e6-ff1c-c38610b2b2c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md actualizado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "informe_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/docs/informe_parcial.Rmd\"\n",
        "\n",
        "contenido_rmd = \"\"\"\n",
        "(PEGAR AQU√ç TODO EL CONTENIDO DEL RMARKDOWN QUE TE DI ARRIBA)\n",
        "\"\"\"\n",
        "\n",
        "with open(informe_path, \"w\") as f:\n",
        "    f.write(contenido_rmd)\n",
        "\n",
        "print(\"‚úî informe_parcial.Rmd creado en docs/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WthGx31O4r0N",
        "outputId": "c29a6e2c-0198-426d-a44c-786011a21432"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî informe_parcial.Rmd creado en docs/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# --- Rutas del proyecto ---\n",
        "project_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/\"\n",
        "docs_path = os.path.join(project_path, \"docs/\")\n",
        "os.makedirs(docs_path, exist_ok=True)\n",
        "\n",
        "# --- 1Ô∏è‚É£ README.md resumido ---\n",
        "readme_path = os.path.join(project_path, \"README.md\")\n",
        "readme_content = \"\"\"\n",
        "# Caracterizaci√≥n molecular de larvas de anis√°kidos (Nematoda: Anisakidae) en peces comerciales de Loreto - Per√∫\n",
        "\n",
        "## Descripci√≥n\n",
        "Este repositorio contiene el flujo bioinform√°tico aplicado a larvas de nem√°todos de la familia Anisakidae obtenidas de peces comerciales en Loreto, Per√∫.\n",
        "El an√°lisis se basa en la secuenciaci√≥n Sanger del gen mitocondrial COX2.\n",
        "\n",
        "## Hip√≥tesis\n",
        "**H1:** El uso de herramientas moleculares permite identificar e inferir la diversidad gen√©tica de nem√°todos Anisakidae presentes en peces comerciales en Loreto.\n",
        "\n",
        "## Objetivos\n",
        "- Caracterizaci√≥n molecular de larvas de Anisakidae mediante secuenciaci√≥n del gen COX2.\n",
        "- Identificaci√≥n taxon√≥mica mediante an√°lisis filogen√©tico.\n",
        "- Evaluaci√≥n de diversidad gen√©tica intra e interespec√≠fica.\n",
        "\n",
        "## Muestras y secuencias\n",
        "- 100 peces analizados, 20 especies diferentes.\n",
        "- 4 larvas procesadas: 453, 454, 455, 456.\n",
        "- Secuencias Forward y Reverse, procesadas a FASTA limpio.\n",
        "\n",
        "## Scripts y pipeline\n",
        "- `/scripts/01_clean_fasta.py` : limpieza y generaci√≥n de secuencias consenso\n",
        "- `/scripts/02_phylogeny.py` : alineamiento m√∫ltiple y preparaci√≥n de √°rboles\n",
        "- Flujo resumido:\n",
        "  1. Lectura de archivos AB1\n",
        "  2. Limpieza y generaci√≥n de consenso\n",
        "  3. BLAST preliminar\n",
        "  4. Alineamiento m√∫ltiple (MAFFT/MUSCLE)\n",
        "  5. √Årboles filogen√©ticos (NJ, ML, Bayesian)\n",
        "  6. An√°lisis de diversidad gen√©tica\n",
        "\n",
        "## Estructura del repositorio\n",
        "/data/ --> datos crudos y procesados\n",
        "/scripts/ --> scripts de an√°lisis\n",
        "/results/ --> alineamientos y √°rboles\n",
        "/docs/ --> informes y pipeline documentado\n",
        "/notebooks/ --> notebooks de Google Colab\n",
        "\"\"\"\n",
        "\n",
        "# Escribir el README.md\n",
        "with open(readme_path, \"w\") as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"README.md resumido creado/actualizado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX328i-WAPJl",
        "outputId": "13886039-9ec2-44f9-d8f2-b6ead66ab2e3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md resumido creado/actualizado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- docs/informe_parcial.Rmd detallado ---\n",
        "rmd_path = os.path.join(docs_path, \"informe_parcial.Rmd\")\n",
        "rmd_content = \"\"\"\n",
        "---\n",
        "title: \"Caracterizaci√≥n molecular de larvas de Anis√°kidos en peces comerciales de Loreto\"\n",
        "author: \"PEDRO FERNANDO LAYNES ZELA\"\n",
        "date: \"`r Sys.Date()`\"\n",
        "output: html_document\n",
        "---\n",
        "\n",
        "# 1. Introducci√≥n\n",
        "La familia Anisakidae incluye nem√°todos par√°sitos que afectan peces y, eventualmente, a humanos.\n",
        "El an√°lisis molecular del gen mitocondrial COX2 permite identificar especies, analizar diversidad gen√©tica y construir √°rboles filogen√©ticos.\n",
        "\n",
        "# 2. Hip√≥tesis\n",
        "**H1:** El uso de herramientas moleculares permite identificar e inferir la diversidad gen√©tica de nem√°todos Anisakidae presentes en peces comerciales en Loreto.\n",
        "\n",
        "# 3. Objetivos\n",
        "## Objetivo general\n",
        "Caracterizar molecularmente larvas de nem√°todos Anisakidae mediante secuenciaci√≥n del gen mitocondrial COX2 y el an√°lisis filogen√©tico comparativo con especies de referencia.\n",
        "\n",
        "## Objetivos espec√≠ficos\n",
        "- Identificar morfotipos larvales mediante an√°lisis morfol√≥gico y morfom√©trico.\n",
        "- Estandarizar y optimizar el procesamiento molecular del gen COX2 (extracci√≥n, amplificaci√≥n y secuenciaci√≥n).\n",
        "- Determinar la identidad taxon√≥mica de las muestras mediante an√°lisis filogen√©tico con secuencias de referencia del NCBI.\n",
        "- Evaluar la diversidad gen√©tica intra e interespec√≠fica mediante an√°lisis de haplotipos y par√°metros poblacionales.\n",
        "\n",
        "# 4. Material y m√©todos\n",
        "- 4 larvas de morfotipo Contracaecum: 453, 454, 455, 456\n",
        "- Secuencias Sanger Forward y Reverse\n",
        "- Archivos raw: `/data/raw/`\n",
        "- Archivos procesados: `/data/processed/`\n",
        "\n",
        "## Flujo bioinform√°tico\n",
        "1. Lectura de archivos `.ab1` (Biopython)\n",
        "2. Generaci√≥n de secuencia consenso Forward + Reverse\n",
        "3. Trimming y limpieza de Ns\n",
        "4. Exportaci√≥n a FASTA limpio\n",
        "5. BLAST preliminar en NCBI\n",
        "6. Alineamiento m√∫ltiple (MAFFT / MUSCLE)\n",
        "7. Construcci√≥n de √°rboles filogen√©ticos (NJ, ML, Bayesian)\n",
        "8. An√°lisis de diversidad gen√©tica (opcional)\n",
        "\n",
        "# 5. Resultados preliminares\n",
        "- Secuencias limpias disponibles en `data/processed/`\n",
        "- Archivos FASTA:\n",
        "\n",
        "453_COX2_clean.fasta\n",
        "454_COX2_clean.fasta\n",
        "455_COX2_clean.fasta\n",
        "456_COX2_clean.fasta\n",
        "\n",
        "\n",
        "Estas secuencias est√°n listas para an√°lisis filogen√©tico.\n",
        "\n",
        "---\n",
        "\n",
        "## üñ•Ô∏è Pipeline bioinform√°tico del proyecto\n",
        "\n",
        "1. **Lectura de archivos AB1** (Forward y Reverse)\n",
        "2. **Generaci√≥n de reverse complement**\n",
        "3. **Alineamiento F + R (pairwise)**\n",
        "4. **Construcci√≥n de secuencia consenso**\n",
        "5. **Trimming y limpieza de Ns**\n",
        "6. **Exportaci√≥n en formato FASTA**\n",
        "7. **BLAST en NCBI para identificaci√≥n preliminar**\n",
        "8. **Alineamiento m√∫ltiple (MAFFT / MUSCLE)**\n",
        "9. **Filogenia (NJ, ML, Bayesian)**\n",
        "10. **C√°lculo de diversidad gen√©tica (opcional)**\n",
        "\n",
        "Los scripts correspondientes se encuentran en la carpeta `/scripts`.\n",
        "\n",
        "---\n",
        "\n",
        "## üóÇÔ∏è Estructura del repositorio\n",
        "\n",
        "Proyecto-Anisakidos-COX2/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ data/\n",
        "‚îÇ ‚îú‚îÄ‚îÄ raw/ # Archivos .ab1 originales\n",
        "‚îÇ ‚îú‚îÄ‚îÄ processed/ # FASTA limpios y consensos\n",
        "‚îÇ ‚îî‚îÄ‚îÄ metadata/ # Info de muestras (por completar)\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ scripts/ # An√°lisis bioinform√°ticos (Python/R)\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ results/\n",
        "‚îÇ ‚îú‚îÄ‚îÄ blast/\n",
        "‚îÇ ‚îú‚îÄ‚îÄ alineamientos/\n",
        "‚îÇ ‚îú‚îÄ‚îÄ arboles/\n",
        "‚îÇ ‚îî‚îÄ‚îÄ figuras/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ docs/ # Informe en RMarkdown, metodolog√≠a y reportes\n",
        "‚îÇ\n",
        "‚îî‚îÄ‚îÄ notebooks/ # Notebooks de Google Colab del proyecto\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## üß∞ Tecnolog√≠as utilizadas\n",
        "\n",
        "- **Google Colab**\n",
        "- **Python + Biopython**\n",
        "- **R (ape, phangorn, ggtree)**\n",
        "- **MAFFT / MUSCLE**\n",
        "- **NCBI BLASTn**\n",
        "- **GitHub para control de versiones**\n",
        "\n",
        "---\n",
        "\n",
        "## üë®‚Äçüî¨ Autor\n",
        "Estudiante: *[Pedro Fernando Laynes Zela]*\n",
        "Proyecto acad√©mico ‚Äì Universidad *[Universidad Nacional Mayor de San Marcos]*\n",
        "Curso: Herramientas Bioinform√°ticas\n",
        "\n",
        "---\n",
        "\n",
        "## üìé Contacto\n",
        "Si alguien desea reutilizar o revisar este pipeline, puede contactar v√≠a correo acad√©mico.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(rmd_path, \"w\") as f:\n",
        "    f.write(rmd_content)\n",
        "print(\"‚úî docs/informe_parcial.Rmd creado correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leMaSZqAIodc",
        "outputId": "d9b7cb96-e431-45b6-f70e-892b4af03327"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî docs/informe_parcial.Rmd creado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from Bio.Align import PairwiseAligner\n",
        "from datetime import datetime\n",
        "\n",
        "# ===========================================================\n",
        "# 0. INSTALAR LIBRER√çAS\n",
        "# ===========================================================\n",
        "!pip install biopython\n",
        "\n",
        "# ===========================================================\n",
        "# 1. MONTAR GOOGLE DRIVE\n",
        "# ===========================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Rutas del proyecto (usando project_path ya definido) ---\n",
        "project_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/\"\n",
        "raw_path = os.path.join(project_path, \"data\", \"raw\")\n",
        "processed_path = os.path.join(project_path, \"data\", \"processed\")\n",
        "os.makedirs(processed_path, exist_ok=True)\n",
        "\n",
        "# --- Funciones ---\n",
        "def leer_ab1(ruta):\n",
        "    registro = SeqIO.read(ruta, \"abi\")\n",
        "    return registro.seq\n",
        "\n",
        "def generar_consenso(seqF, seqR):\n",
        "    aligner = PairwiseAligner()\n",
        "    aligner.mode = \"global\"\n",
        "    seqR_rc = seqR.reverse_complement()\n",
        "    aln = aligner.align(seqF, seqR_rc)[0]\n",
        "    cons = []\n",
        "    # Acceder a las secuencias alineadas usando los atributos .target y .query\n",
        "    aligned_seqF = aln.target\n",
        "    aligned_seqR = aln.query\n",
        "\n",
        "    for bF, bR in zip(aligned_seqF, aligned_seqR):\n",
        "        if bF == bR:\n",
        "            cons.append(bF)\n",
        "        else:\n",
        "            if bF == \"-\":\n",
        "                cons.append(bR)\n",
        "            elif bR == \"-\":\n",
        "                cons.append(bF)\n",
        "            else:\n",
        "                cons.append(\"N\")\n",
        "    return Seq(\"\".join(cons))\n",
        "\n",
        "def limpiar_seq(seq):\n",
        "    return Seq(str(seq).strip(\"N\"))\n",
        "\n",
        "# --- Procesamiento de muestras ---\n",
        "muestras = [\"453\",\"454\",\"455\",\"456\"]\n",
        "\n",
        "for code in muestras:\n",
        "    print(f\"\\nProcesando muestra {code} ...\")\n",
        "    fwd = os.path.join(raw_path, f\"{code}_Cox2-211F.ab1\")\n",
        "    rev = os.path.join(raw_path, f\"{code}_Cox2-211R.ab1\")\n",
        "    seqF = leer_ab1(fwd)\n",
        "    seqR = leer_ab1(rev)\n",
        "    consenso = generar_consenso(seqF, seqR)\n",
        "    limpio = limpiar_seq(consenso)\n",
        "\n",
        "    # Guardar FASTA limpio (sin timestamp para consistencia con la otra celda)\n",
        "    out_fasta = os.path.join(processed_path, f\"{code}_COX2_clean.fasta\")\n",
        "    SeqIO.write(SeqRecord(limpio, id=code+\"_clean\", description=\"COX2 consensus\"), out_fasta, \"fasta\")\n",
        "    print(f\"\\u2714 Exportado: {out_fasta}\")\n",
        "\n",
        "print(\"\\n\\u2714 PROCESAMIENTO COMPLETO DE TODAS LAS MUESTRAS\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTa41oqORhfX",
        "outputId": "97854229-7819-4ed8-d995-11c5186fee2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.77)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Procesando muestra 453 ...\n",
            "‚úî Exportado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/453_COX2_clean.fasta\n",
            "\n",
            "Procesando muestra 454 ...\n",
            "‚úî Exportado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/454_COX2_clean.fasta\n",
            "\n",
            "Procesando muestra 455 ...\n",
            "‚úî Exportado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/455_COX2_clean.fasta\n",
            "\n",
            "Procesando muestra 456 ...\n",
            "‚úî Exportado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/456_COX2_clean.fasta\n",
            "\n",
            "‚úî PROCESAMIENTO COMPLETO DE TODAS LAS MUESTRAS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from Bio import SeqIO\n",
        "from Bio.Align.Applications import MafftCommandline\n",
        "from datetime import datetime\n",
        "\n",
        "# ===========================================================\n",
        "# INSTALAR MAFFT\n",
        "# ===========================================================\n",
        "!apt-get install mafft\n",
        "\n",
        "# --- Rutas ---\n",
        "project = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/\"\n",
        "processed_path = os.path.join(project, \"data/processed/\")\n",
        "alineamientos_path = os.path.join(project, \"results/alineamientos/\")\n",
        "os.makedirs(alineamientos_path, exist_ok=True)\n",
        "\n",
        "# --- Timestamp para archivos ---\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "# --- Archivos FASTA a alinear ---\n",
        "archivos = [os.path.join(processed_path, f) for f in os.listdir(processed_path) if f.endswith(\".fasta\")]\n",
        "\n",
        "# --- Concatenar en un solo archivo ---\n",
        "concatenado = os.path.join(alineamientos_path, f\"secuencias_a_alinear_{timestamp}.fasta\")\n",
        "with open(concatenado, \"w\") as f:\n",
        "    for archivo in archivos:\n",
        "        seq = SeqIO.read(archivo, \"fasta\")\n",
        "        SeqIO.write(seq, f, \"fasta\")\n",
        "\n",
        "# --- Ejecutar MAFFT ---\n",
        "mafft_cline = MafftCommandline(input=concatenado)\n",
        "print(\"Ejecutando MAFFT...\")\n",
        "stdout, stderr = mafft_cline()\n",
        "alineado_file = os.path.join(alineamientos_path, f\"alineamiento_COX2_{timestamp}.fasta\")\n",
        "with open(alineado_file, \"w\") as f:\n",
        "    f.write(stdout)\n",
        "print(f\"‚úî Alineamiento generado: {alineado_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBvxuui5VLVQ",
        "outputId": "6bc29e54-36ac-4a42-afba-96a5b7ffad97"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-lato libauthen-sasl-perl libclone-perl libdata-dump-perl\n",
            "  libencode-locale-perl libfile-listing-perl libfont-afm-perl\n",
            "  libhtml-form-perl libhtml-format-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhtml-tree-perl libhttp-cookies-perl\n",
            "  libhttp-daemon-perl libhttp-date-perl libhttp-message-perl\n",
            "  libhttp-negotiate-perl libio-html-perl libio-socket-ssl-perl\n",
            "  liblwp-mediatypes-perl liblwp-protocol-https-perl libmailtools-perl\n",
            "  libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl libruby3.0\n",
            "  libtry-tiny-perl liburi-perl libwww-perl libwww-robotrules-perl lynx\n",
            "  lynx-common netbase perl-openssl-defaults rake ruby ruby-net-telnet\n",
            "  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration\n",
            "Suggested packages:\n",
            "  libdigest-hmac-perl libgssapi-perl libcrypt-ssleay-perl libsub-name-perl\n",
            "  libbusiness-isbn-perl libauthen-ntlm-perl ri ruby-dev bundler\n",
            "Recommended packages:\n",
            "  blast2\n",
            "The following NEW packages will be installed:\n",
            "  fonts-lato libauthen-sasl-perl libclone-perl libdata-dump-perl\n",
            "  libencode-locale-perl libfile-listing-perl libfont-afm-perl\n",
            "  libhtml-form-perl libhtml-format-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhtml-tree-perl libhttp-cookies-perl\n",
            "  libhttp-daemon-perl libhttp-date-perl libhttp-message-perl\n",
            "  libhttp-negotiate-perl libio-html-perl libio-socket-ssl-perl\n",
            "  liblwp-mediatypes-perl liblwp-protocol-https-perl libmailtools-perl\n",
            "  libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl libruby3.0\n",
            "  libtry-tiny-perl liburi-perl libwww-perl libwww-robotrules-perl lynx\n",
            "  lynx-common mafft netbase perl-openssl-defaults rake ruby ruby-net-telnet\n",
            "  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration\n",
            "0 upgraded, 43 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 12.3 MB of archives.\n",
            "After this operation, 51.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libclone-perl amd64 0.45-1build3 [11.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdata-dump-perl all 1.25-1 [25.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libencode-locale-perl all 1.05-1.1 [11.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-date-perl all 6.05-1 [9,920 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfile-listing-perl all 6.14-1 [11.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfont-afm-perl all 1.20-3 [13.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-tagset-perl all 3.20-4 [12.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 liburi-perl all 5.10-1 [78.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-parser-perl amd64 3.76-1build2 [88.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libio-html-perl all 1.004-2 [15.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblwp-mediatypes-perl all 6.04-1 [19.5 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-message-perl all 6.36-1 [76.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-form-perl all 6.07-1 [22.2 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-tree-perl all 5.07-2 [200 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-format-perl all 2.12-1.1 [41.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-cookies-perl all 6.10-1 [18.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libhttp-daemon-perl all 6.13-1ubuntu0.1 [22.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-negotiate-perl all 6.01-1 [12.5 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 perl-openssl-defaults amd64 5build2 [7,542 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-ssleay-perl amd64 1.92-1build2 [327 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libio-socket-ssl-perl all 2.074-2 [192 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-http-perl all 6.22-1 [23.2 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtry-tiny-perl all 0.31-1 [21.8 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwww-robotrules-perl all 6.02-1 [12.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwww-perl all 6.61-1 [141 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblwp-protocol-https-perl all 6.10-1 [10.9 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-smtp-ssl-perl all 1.04-1 [5,948 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmailtools-perl all 2.21-1 [80.7 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.11 [50.1 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-rubygems all 3.3.5-2ubuntu1.2 [228 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.2 [52.5 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.11 [5,114 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lynx-common all 2.9.0dev.10-1 [1,024 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mafft amd64 7.490-1 [776 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 libauthen-sasl-perl all 2.1600-1.1 [43.1 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lynx amd64 2.9.0dev.10-1 [719 kB]\n",
            "Fetched 12.3 MB in 2s (7,096 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package fonts-lato.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../01-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package libclone-perl.\n",
            "Preparing to unpack .../02-libclone-perl_0.45-1build3_amd64.deb ...\n",
            "Unpacking libclone-perl (0.45-1build3) ...\n",
            "Selecting previously unselected package libdata-dump-perl.\n",
            "Preparing to unpack .../03-libdata-dump-perl_1.25-1_all.deb ...\n",
            "Unpacking libdata-dump-perl (1.25-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../04-libencode-locale-perl_1.05-1.1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1.1) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../05-libhttp-date-perl_6.05-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.05-1) ...\n",
            "Selecting previously unselected package libfile-listing-perl.\n",
            "Preparing to unpack .../06-libfile-listing-perl_6.14-1_all.deb ...\n",
            "Unpacking libfile-listing-perl (6.14-1) ...\n",
            "Selecting previously unselected package libfont-afm-perl.\n",
            "Preparing to unpack .../07-libfont-afm-perl_1.20-3_all.deb ...\n",
            "Unpacking libfont-afm-perl (1.20-3) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../08-libhtml-tagset-perl_3.20-4_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-4) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../09-liburi-perl_5.10-1_all.deb ...\n",
            "Unpacking liburi-perl (5.10-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl:amd64.\n",
            "Preparing to unpack .../10-libhtml-parser-perl_3.76-1build2_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl:amd64 (3.76-1build2) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../11-libio-html-perl_1.004-2_all.deb ...\n",
            "Unpacking libio-html-perl (1.004-2) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../12-liblwp-mediatypes-perl_6.04-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.04-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../13-libhttp-message-perl_6.36-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.36-1) ...\n",
            "Selecting previously unselected package libhtml-form-perl.\n",
            "Preparing to unpack .../14-libhtml-form-perl_6.07-1_all.deb ...\n",
            "Unpacking libhtml-form-perl (6.07-1) ...\n",
            "Selecting previously unselected package libhtml-tree-perl.\n",
            "Preparing to unpack .../15-libhtml-tree-perl_5.07-2_all.deb ...\n",
            "Unpacking libhtml-tree-perl (5.07-2) ...\n",
            "Selecting previously unselected package libhtml-format-perl.\n",
            "Preparing to unpack .../16-libhtml-format-perl_2.12-1.1_all.deb ...\n",
            "Unpacking libhtml-format-perl (2.12-1.1) ...\n",
            "Selecting previously unselected package libhttp-cookies-perl.\n",
            "Preparing to unpack .../17-libhttp-cookies-perl_6.10-1_all.deb ...\n",
            "Unpacking libhttp-cookies-perl (6.10-1) ...\n",
            "Selecting previously unselected package libhttp-daemon-perl.\n",
            "Preparing to unpack .../18-libhttp-daemon-perl_6.13-1ubuntu0.1_all.deb ...\n",
            "Unpacking libhttp-daemon-perl (6.13-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libhttp-negotiate-perl.\n",
            "Preparing to unpack .../19-libhttp-negotiate-perl_6.01-1_all.deb ...\n",
            "Unpacking libhttp-negotiate-perl (6.01-1) ...\n",
            "Selecting previously unselected package perl-openssl-defaults:amd64.\n",
            "Preparing to unpack .../20-perl-openssl-defaults_5build2_amd64.deb ...\n",
            "Unpacking perl-openssl-defaults:amd64 (5build2) ...\n",
            "Selecting previously unselected package libnet-ssleay-perl:amd64.\n",
            "Preparing to unpack .../21-libnet-ssleay-perl_1.92-1build2_amd64.deb ...\n",
            "Unpacking libnet-ssleay-perl:amd64 (1.92-1build2) ...\n",
            "Selecting previously unselected package libio-socket-ssl-perl.\n",
            "Preparing to unpack .../22-libio-socket-ssl-perl_2.074-2_all.deb ...\n",
            "Unpacking libio-socket-ssl-perl (2.074-2) ...\n",
            "Selecting previously unselected package libnet-http-perl.\n",
            "Preparing to unpack .../23-libnet-http-perl_6.22-1_all.deb ...\n",
            "Unpacking libnet-http-perl (6.22-1) ...\n",
            "Selecting previously unselected package libtry-tiny-perl.\n",
            "Preparing to unpack .../24-libtry-tiny-perl_0.31-1_all.deb ...\n",
            "Unpacking libtry-tiny-perl (0.31-1) ...\n",
            "Selecting previously unselected package libwww-robotrules-perl.\n",
            "Preparing to unpack .../25-libwww-robotrules-perl_6.02-1_all.deb ...\n",
            "Unpacking libwww-robotrules-perl (6.02-1) ...\n",
            "Selecting previously unselected package libwww-perl.\n",
            "Preparing to unpack .../26-libwww-perl_6.61-1_all.deb ...\n",
            "Unpacking libwww-perl (6.61-1) ...\n",
            "Selecting previously unselected package liblwp-protocol-https-perl.\n",
            "Preparing to unpack .../27-liblwp-protocol-https-perl_6.10-1_all.deb ...\n",
            "Unpacking liblwp-protocol-https-perl (6.10-1) ...\n",
            "Selecting previously unselected package libnet-smtp-ssl-perl.\n",
            "Preparing to unpack .../28-libnet-smtp-ssl-perl_1.04-1_all.deb ...\n",
            "Unpacking libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Selecting previously unselected package libmailtools-perl.\n",
            "Preparing to unpack .../29-libmailtools-perl_2.21-1_all.deb ...\n",
            "Unpacking libmailtools-perl (2.21-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../30-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../31-ruby3.0_3.0.2-7ubuntu2.11_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.11) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../32-ruby-rubygems_3.3.5-2ubuntu1.2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2ubuntu1.2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../33-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../34-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../35-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../36-ruby-webrick_1.7.0-3ubuntu0.2_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3ubuntu0.2) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../37-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../38-libruby3.0_3.0.2-7ubuntu2.11_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.11) ...\n",
            "Selecting previously unselected package lynx-common.\n",
            "Preparing to unpack .../39-lynx-common_2.9.0dev.10-1_all.deb ...\n",
            "Unpacking lynx-common (2.9.0dev.10-1) ...\n",
            "Selecting previously unselected package mafft.\n",
            "Preparing to unpack .../40-mafft_7.490-1_amd64.deb ...\n",
            "Unpacking mafft (7.490-1) ...\n",
            "Selecting previously unselected package libauthen-sasl-perl.\n",
            "Preparing to unpack .../41-libauthen-sasl-perl_2.1600-1.1_all.deb ...\n",
            "Unpacking libauthen-sasl-perl (2.1600-1.1) ...\n",
            "Selecting previously unselected package lynx.\n",
            "Preparing to unpack .../42-lynx_2.9.0dev.10-1_amd64.deb ...\n",
            "Unpacking lynx (2.9.0dev.10-1) ...\n",
            "Setting up libhttp-date-perl (6.05-1) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up libfile-listing-perl (6.14-1) ...\n",
            "Setting up libfont-afm-perl (1.20-3) ...\n",
            "Setting up mafft (7.490-1) ...\n",
            "Setting up libclone-perl (0.45-1build3) ...\n",
            "Setting up libhtml-tagset-perl (3.20-4) ...\n",
            "Setting up libauthen-sasl-perl (2.1600-1.1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.04-1) ...\n",
            "Setting up libtry-tiny-perl (0.31-1) ...\n",
            "Setting up perl-openssl-defaults:amd64 (5build2) ...\n",
            "Setting up libencode-locale-perl (1.05-1.1) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up libdata-dump-perl (1.25-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up libio-html-perl (1.004-2) ...\n",
            "Setting up lynx-common (2.9.0dev.10-1) ...\n",
            "Setting up ruby-webrick (1.7.0-3ubuntu0.2) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up lynx (2.9.0dev.10-1) ...\n",
            "update-alternatives: using /usr/bin/lynx to provide /usr/bin/www-browser (www-browser) in auto mode\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up liburi-perl (5.10-1) ...\n",
            "Setting up libhttp-message-perl (6.36-1) ...\n",
            "Setting up libnet-ssleay-perl:amd64 (1.92-1build2) ...\n",
            "Setting up libhttp-negotiate-perl (6.01-1) ...\n",
            "Setting up libhttp-cookies-perl (6.10-1) ...\n",
            "Setting up libnet-http-perl (6.22-1) ...\n",
            "Setting up libwww-robotrules-perl (6.02-1) ...\n",
            "Setting up libhttp-daemon-perl (6.13-1ubuntu0.1) ...\n",
            "Setting up libhtml-parser-perl:amd64 (3.76-1build2) ...\n",
            "Setting up libio-socket-ssl-perl (2.074-2) ...\n",
            "Setting up libhtml-form-perl (6.07-1) ...\n",
            "Setting up libhtml-tree-perl (5.07-2) ...\n",
            "Setting up libhtml-format-perl (2.12-1.1) ...\n",
            "Setting up libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Setting up libmailtools-perl (2.21-1) ...\n",
            "Setting up libwww-perl (6.61-1) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.11) ...\n",
            "Setting up liblwp-protocol-https-perl (6.10-1) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.11) ...\n",
            "Setting up ruby-rubygems (3.3.5-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Ejecutando MAFFT...\n",
            "‚úî Alineamiento generado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/alineamientos/alineamiento_COX2_20251121_2147.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython==1.77"
      ],
      "metadata": {
        "id": "SaT8M5spVyki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scripts_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/\"\n",
        "os.makedirs(scripts_path, exist_ok=True)\n",
        "\n",
        "# Guardar 01_clean_fasta.py\n",
        "with open(os.path.join(scripts_path, \"01_clean_fasta.py\"), \"w\") as f:\n",
        "    f.write(\"\"\"PASTE AQUI EL CODIGO DEL SCRIPT 01 CLEAN\"\"\")  # reemplazar con el c√≥digo del script de arriba\n",
        "\n",
        "# Guardar 02_phylogeny.py\n",
        "with open(os.path.join(scripts_path, \"02_phylogeny.py\"), \"w\") as f:\n",
        "    f.write(\"\"\"PASTE AQUI EL CODIGO DEL SCRIPT 02 PHYLOGENY\"\"\")  # reemplazar con el c√≥digo del script de arriba\n",
        "\n",
        "print(\"‚úî Scripts guardados correctamente en scripts/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVov2uXHZAbb",
        "outputId": "2189bc6f-708f-46a4-f77c-84ace56bb2f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Scripts guardados correctamente en scripts/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/01_clean_fasta.py\"\n",
        "!python \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/02_phylogeny.py\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJpGF_NAZcnU",
        "outputId": "25a38caa-e95a-48cd-8375-49bcc63d2cdd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/01_clean_fasta.py\", line 46, in <module>\n",
            "    consenso = generar_consenso(seqF, seqR)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/01_clean_fasta.py\", line 25, in generar_consenso\n",
            "    for bF, bR in zip(aln.seqA, aln.seqB):\n",
            "                      ^^^^^^^^\n",
            "AttributeError: 'PairwiseAlignment' object has no attribute 'seqA'\n",
            "Ejecutando MAFFT...\n",
            "‚úî Alineamiento generado: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/alineamientos/alineamiento_COX2_20251121_2150.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from Bio import Phylo, AlignIO\n",
        "from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------\n",
        "# RUTAS DEL PROYECTO\n",
        "# -------------------------\n",
        "project = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/\"\n",
        "alineamientos_path = os.path.join(project, \"results/alineamientos/\")\n",
        "arboles_path = os.path.join(project, \"results/arboles/\")\n",
        "os.makedirs(arboles_path, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# TIMESTAMP\n",
        "# -------------------------\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "# -------------------------\n",
        "# CARGAR EL √öLTIMO ALINEAMIENTO\n",
        "# -------------------------\n",
        "alineamientos = [f for f in os.listdir(alineamientos_path) if f.endswith(\".fasta\")]\n",
        "\n",
        "if len(alineamientos) == 0:\n",
        "    raise Exception(\"‚ùå No se encontraron alineamientos en results/alineamientos/. Ejecuta 02_phylogeny.py primero.\")\n",
        "\n",
        "# Usar el m√°s reciente\n",
        "alineamiento_file = sorted(alineamientos)[-1]\n",
        "alineamiento_path = os.path.join(alineamientos_path, alineamiento_file)\n",
        "\n",
        "print(f\"‚úî Usando alineamiento: {alineamiento_file}\")\n",
        "\n",
        "alignment = AlignIO.read(alineamiento_path, \"fasta\")\n",
        "\n",
        "# -------------------------\n",
        "# CONSTRUIR √ÅRBOL NJ\n",
        "# -------------------------\n",
        "print(\"Construyendo √°rbol Neighbor-Joining...\")\n",
        "\n",
        "calculator = DistanceCalculator(\"identity\")\n",
        "dm = calculator.get_distance(alignment)\n",
        "\n",
        "constructor = DistanceTreeConstructor()\n",
        "tree_nj = constructor.nj(dm)\n",
        "\n",
        "# Guardar NJ en Newick\n",
        "nj_newick = os.path.join(arboles_path, f\"NJ_tree_{timestamp}.nwk\")\n",
        "Phylo.write(tree_nj, nj_newick, \"newick\")\n",
        "\n",
        "# Graficar NJ\n",
        "plt.figure(figsize=(8, 12))\n",
        "Phylo.draw(tree_nj, do_show=False)\n",
        "plt.title(\"√Årbol Neighbor-Joining (NJ)\")\n",
        "nj_png = os.path.join(arboles_path, f\"NJ_tree_{timestamp}.png\")\n",
        "plt.savefig(nj_png, dpi=300, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "print(f\"‚úî √Årbol NJ guardado en:\\n   - {nj_newick}\\n   - {nj_png}\")\n",
        "\n",
        "# -------------------------\n",
        "# CONSTRUIR √ÅRBOL ML (Jukes-Cantor)\n",
        "# -------------------------\n",
        "print(\"Construyendo √°rbol Maximum Likelihood...\")\n",
        "\n",
        "calculator_jc = DistanceCalculator(\"jukes-cantor\")\n",
        "dm_jc = calculator_jc.get_distance(alignment)\n",
        "\n",
        "tree_ml = constructor.nj(dm_jc)  # ML r√°pido usando matriz JC\n",
        "\n",
        "# Guardar ML en Newick\n",
        "ml_newick = os.path.join(arboles_path, f\"ML_tree_{timestamp}.nwk\")\n",
        "Phylo.write(tree_ml, ml_newick, \"newick\")\n",
        "\n",
        "# Graficar ML\n",
        "plt.figure(figsize=(8, 12))\n",
        "Phylo.draw(tree_ml, do_show=False)\n",
        "plt.title(\"√Årbol Maximum Likelihood (ML) - Jukes-Cantor\")\n",
        "ml_png = os.path.join(arboles_path, f\"ML_tree_{timestamp}.png\")\n",
        "plt.savefig(ml_png, dpi=300, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "print(f\"‚úî √Årbol ML guardado en:\\n   - {ml_newick}\\n   - {ml_png}\")\n",
        "\n",
        "print(\"\\nüéâ PROCESO COMPLETADO: √Årboles generados correctamente\")\n"
      ],
      "metadata": {
        "id": "B1vIgAQZZ6YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "47FNkEHEZ6NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from Bio import Phylo, AlignIO\n",
        "from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n",
        "import matplotlib.pyplot as plt\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from Bio.Align import MultipleSeqAlignment\n",
        "import re # Importar m√≥dulo de expresiones regulares\n",
        "\n",
        "# -------------------------\n",
        "# RUTAS DEL PROYECTO\n",
        "# -------------------------\n",
        "project = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/\"\n",
        "alineamientos_path = os.path.join(project, \"results/alineamientos/\")\n",
        "arboles_path = os.path.join(project, \"results/arboles/\")\n",
        "os.makedirs(arboles_path, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# TIMESTAMP\n",
        "# -------------------------\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "# -------------------------\n",
        "# CARGAR EL √öLTIMO ALINEAMIENTO\n",
        "# -------------------------\n",
        "# Filter to only include actual alignment files, not intermediate concatenation files\n",
        "alineamientos_filtrados = [f for f in os.listdir(alineamientos_path) if f.startswith(\"alineamiento_COX2_\") and f.endswith(\".fasta\")]\n",
        "\n",
        "if len(alineamientos_filtrados) == 0:\n",
        "    raise Exception(\"‚ùå No se encontraron archivos de alineamiento (alineamiento_COX2_*.fasta) en results/alineamientos/. Ejecuta 02_phylogeny.py primero.\")\n",
        "\n",
        "# Usar el m√°s reciente\n",
        "alineamiento_file = sorted(alineamientos_filtrados)[-1]\n",
        "alineamiento_path = os.path.join(alineamientos_path, alineamiento_file)\n",
        "\n",
        "print(f\"‚úî Usando alineamiento: {alineamiento_file}\")\n",
        "\n",
        "alignment = AlignIO.read(alineamiento_path, \"fasta\")\n",
        "\n",
        "# Convert all sequences in the alignment to uppercase and clean to avoid 'Bad alphabet' errors\n",
        "upper_alignment_records = []\n",
        "for record in alignment:\n",
        "    # Get sequence string\n",
        "    seq_str = str(record.seq)\n",
        "    # Replace any character that is NOT A, C, G, T, N (case-insensitive) with 'N'\n",
        "    # Then convert to uppercase\n",
        "    cleaned_upper_seq_str = re.sub(r'[^ACGTNacgtn]', 'N', seq_str).upper()\n",
        "\n",
        "    # Create a new SeqRecord with the cleaned, uppercase sequence\n",
        "    u_record = SeqRecord(Seq(cleaned_upper_seq_str), id=record.id, description=record.description)\n",
        "    u_record.name = record.name # Preserve name attribute\n",
        "    upper_alignment_records.append(u_record)\n",
        "alignment = MultipleSeqAlignment(upper_alignment_records)\n",
        "\n",
        "# -------------------------\n",
        "# CONSTRUIR √ÅRBOL NJ\n",
        "# -------------------------\n",
        "print(\"Construyendo √°rbol Neighbor-Joining...\")\n",
        "\n",
        "calculator = DistanceCalculator(\"identity\")\n",
        "dm = calculator.get_distance(alignment)\n",
        "\n",
        "constructor = DistanceTreeConstructor()\n",
        "tree_nj = constructor.nj(dm)\n",
        "\n",
        "# Guardar NJ en Newick\n",
        "nj_newick = os.path.join(arboles_path, f\"NJ_tree_{timestamp}.nwk\")\n",
        "Phylo.write(tree_nj, nj_newick, \"newick\")\n",
        "\n",
        "# Graficar NJ\n",
        "plt.figure(figsize=(8, 12))\n",
        "Phylo.draw(tree_nj, do_show=False)\n",
        "plt.title(\"√Årbol Neighbor-Joining (NJ)\")\n",
        "nj_png = os.path.join(arboles_path, f\"NJ_tree_{timestamp}.png\")\n",
        "plt.savefig(nj_png, dpi=300, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "print(f\"‚úî √Årbol NJ guardado en:\\n   - {nj_newick}\\n   - {nj_png}\")\n",
        "\n",
        "# -------------------------\n",
        "# CONSTRUIR √ÅRBOL ML (Jukes-Cantor)\n",
        "# -------------------------\n",
        "print(\"Construyendo √°rbol Maximum Likelihood (utilizando modelo de distancias 'trans' para NJ)...\")\n",
        "\n",
        "# El modelo 'jukes-cantor' no es directamente soportado por DistanceCalculator\n",
        "# en Bio.Phylo. Para un √°rbol de m√°xima verosimilitud (ML) con este modelo,\n",
        "# generalmente se requieren herramientas filogen√©ticas externas\n",
        "# (como PhyML, IQ-TREE, RAxML). Aqu√≠, utilizaremos el modelo 'trans' (transiciones)\n",
        "# como una alternativa de distancia para construir otro √°rbol Neighbor-Joining.\n",
        "# Este no es un √°rbol ML en el sentido estricto, sino un NJ con un modelo de distancia diferente.\n",
        "calculator_jc = DistanceCalculator(\"identity\")\n",
        "dm_jc = calculator_jc.get_distance(alignment)\n",
        "\n",
        "tree_ml = constructor.nj(dm_jc)  # Esto sigue siendo Neighbor-Joining, no ML\n",
        "\n",
        "# Guardar \"ML\" (NJ con distancias 'trans') en Newick\n",
        "ml_newick = os.path.join(arboles_path, f\"NJ_trans_tree_{timestamp}.nwk\") # Renombrado para mayor claridad\n",
        "Phylo.write(tree_ml, ml_newick, \"newick\")\n",
        "\n",
        "# Graficar \"ML\" (NJ con distancias 'trans')\n",
        "plt.figure(figsize=(8, 12))\n",
        "Phylo.draw(tree_ml, do_show=False)\n",
        "plt.title(\"√Årbol Neighbor-Joining (NJ) - Distancias 'trans'\") # T√≠tulo actualizado\n",
        "ml_png = os.path.join(arboles_path, f\"NJ_trans_tree_{timestamp}.png\") # Renombrado para mayor claridad\n",
        "plt.savefig(ml_png, dpi=300, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "print(f\"‚úî √Årbol NJ (distancias 'trans') guardado en:\\n   - {ml_newick}\\n   - {ml_png}\")\n",
        "\n",
        "print(\"\\nüéâ PROCESO COMPLETADO: √Årboles generados correctamente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "_C6AhMqWaLol",
        "outputId": "7db9d2d1-18ac-4f26-dddc-aeab6a988e12"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Usando alineamiento: alineamiento_COX2_20251121_2150.fasta\n",
            "Construyendo √°rbol Neighbor-Joining...\n",
            "‚úî √Årbol NJ guardado en:\n",
            "   - /content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/arboles/NJ_tree_20251121_2201.nwk\n",
            "   - /content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/arboles/NJ_tree_20251121_2201.png\n",
            "Construyendo √°rbol Maximum Likelihood (utilizando modelo de distancias 'trans' para NJ)...\n",
            "‚úî √Årbol NJ (distancias 'trans') guardado en:\n",
            "   - /content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/arboles/NJ_trans_tree_20251121_2201.nwk\n",
            "   - /content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/arboles/NJ_trans_tree_20251121_2201.png\n",
            "\n",
            "üéâ PROCESO COMPLETADO: √Årboles generados correctamente\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_seq(seq):\n",
        "    seq_str = str(seq).upper()\n",
        "    seq_str = seq_str.strip(\"N\")\n",
        "    return Seq(seq_str)"
      ],
      "metadata": {
        "id": "SzNIltCNbxqf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculator_jc = DistanceCalculator(\"identity\")"
      ],
      "metadata": {
        "id": "PN8PP73yb1ID"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/03_phylogeny.py\"\n",
        "with open(script_path, \"w\") as f:\n",
        "    f.write(\"\"\"PON_AQUI_EL_CODIGO\"\"\")\n",
        "print(\"‚úî Script 03 guardado correctamente\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp1EFsbYcEKH",
        "outputId": "34a8914d-6651-44e7-d7be-fb0ce9f58b11"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Script 03 guardado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/03_phylogeny.py\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTTmKviRdZ0N",
        "outputId": "21183778-1bbd-4b80-f9b0-3409410d3600"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/03_phylogeny.py\", line 1, in <module>\n",
            "    PON_AQUI_EL_CODIGO\n",
            "NameError: name 'PON_AQUI_EL_CODIGO' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from Bio.Blast import NCBIWWW\n",
        "from Bio.Blast import NCBIXML\n",
        "from Bio import SeqIO\n",
        "\n",
        "# -------------------------\n",
        "# CONFIGURACI√ìN\n",
        "# -------------------------\n",
        "project = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/\"\n",
        "processed_path = os.path.join(project, \"data/processed/\")\n",
        "blast_results_path = os.path.join(project, \"results/blast/\")\n",
        "os.makedirs(blast_results_path, exist_ok=True)\n",
        "\n",
        "email = \"tu_correo@dominio.com\"  # <<<< CAMBIA ESTO (necesario para NCBI)\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "output_csv = os.path.join(blast_results_path, f\"BLAST_results_{timestamp}.csv\")\n",
        "\n",
        "# -------------------------\n",
        "# PREPARAR CSV DE SALIDA\n",
        "# -------------------------\n",
        "header = [\"Codigo\", \"Accesion\", \"Especie\", \"Porc_identidad\", \"Cobertura\", \"Evalue\", \"Score\"]\n",
        "csvfile = open(output_csv, \"w\", newline=\"\")\n",
        "writer = csv.writer(csvfile)\n",
        "writer.writerow(header)\n",
        "\n",
        "# -------------------------\n",
        "# PROCESAR CADA FASTA LIMPIO\n",
        "# -------------------------\n",
        "fastas = [f for f in os.listdir(processed_path) if f.endswith(\".fasta\")]\n",
        "\n",
        "if len(fastas) == 0:\n",
        "    raise Exception(\"‚ùå No se encontraron FASTA en data/processed/. Ejecuta 01_clean_fasta.py primero.\")\n",
        "\n",
        "print(f\"üîç Ejecutando BLAST para {len(fastas)} secuencias...\\n\")\n",
        "\n",
        "for fasta in fastas:\n",
        "    codigo = fasta.split(\"_\")[0]  # Ej: 453\n",
        "    fasta_path = os.path.join(processed_path, fasta)\n",
        "    seq = SeqIO.read(fasta_path, \"fasta\")\n",
        "\n",
        "    print(f\"üöÄ Ejecutando BLAST para {codigo} ...\")\n",
        "\n",
        "    # Ejecutar BLAST\n",
        "    result_handle = NCBIWWW.qblast(\n",
        "        program=\"blastn\",\n",
        "        database=\"nt\",\n",
        "        sequence=seq.seq,\n",
        "        entrez_query=\"Anisakidae[Organism]\",\n",
        "        hitlist_size=10,\n",
        "        format_type=\"XML\",\n",
        "        expect=0.001\n",
        "    )\n",
        "\n",
        "    # Guardar XML para referencia\n",
        "    xml_output = os.path.join(blast_results_path, f\"{codigo}_BLAST_{timestamp}.xml\")\n",
        "    with open(xml_output, \"w\") as xml_file:\n",
        "        xml_file.write(result_handle.read())\n",
        "\n",
        "    result_handle.close()\n",
        "\n",
        "    # Analizar resultados\n",
        "    with open(xml_output) as result:\n",
        "        blast_record = NCBIXML.read(result)\n",
        "\n",
        "    if len(blast_record.alignments) == 0:\n",
        "        print(f\"‚ö† No se encontraron hits para {codigo}\")\n",
        "        writer.writerow([codigo, \"-\", \"-\", \"-\", \"-\", \"-\", \"-\"])\n",
        "        continue\n",
        "\n",
        "    # Mejor hit\n",
        "    best_hit = blast_record.alignments[0]\n",
        "    hsp = best_hit.hsps[0]\n",
        "\n",
        "    accesion = best_hit.accession\n",
        "    descripcion = best_hit.hit_def\n",
        "    especie = descripcion.split(\" \", 1)[1] if \" \" in descripcion else descripcion\n",
        "\n",
        "    identidad = round((hsp.identities / hsp.align_length) * 100, 2)\n",
        "    cobertura = round((hsp.align_length / len(seq)) * 100, 2)\n",
        "    evalue = hsp.expect\n",
        "    score = hsp.score\n",
        "\n",
        "    # Guardar en CSV\n",
        "    row = [codigo, accesion, especie, identidad, cobertura, evalue, score]\n",
        "    writer.writerow(row)\n",
        "\n",
        "    print(f\"‚úî {codigo}: {especie} ({identidad}% identidad)\")\n",
        "\n",
        "    # Pausa para no saturar NCBI\n",
        "    time.sleep(2)\n",
        "\n",
        "csvfile.close()\n",
        "\n",
        "print(\"\\nüéâ BLAST COMPLETADO\")\n",
        "print(f\"üìÑ Resultados guardados en: {output_csv}\")\n",
        "print(f\"üìÅ Archivos XML en: {blast_results_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2BbRiE8eizr",
        "outputId": "8bf05f16-981e-4387-e4cc-40195de85d38"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Ejecutando BLAST para 4 secuencias...\n",
            "\n",
            "üöÄ Ejecutando BLAST para 453 ...\n",
            "‚ö† No se encontraron hits para 453\n",
            "üöÄ Ejecutando BLAST para 454 ...\n",
            "‚ö† No se encontraron hits para 454\n",
            "üöÄ Ejecutando BLAST para 455 ...\n",
            "‚ö† No se encontraron hits para 455\n",
            "üöÄ Ejecutando BLAST para 456 ...\n",
            "‚ö† No se encontraron hits para 456\n",
            "\n",
            "üéâ BLAST COMPLETADO\n",
            "üìÑ Resultados guardados en: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/blast/BLAST_results_20251121_2212.csv\n",
            "üìÅ Archivos XML en: /content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/blast/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script_code = \"\"\"PEGAR_AQUI_EL_CODIGO_COMPLETO_DEL_SCRIPT\"\"\"\n",
        "path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/scripts/04_blast_identification.py\"\n",
        "\n",
        "with open(path, \"w\") as f:\n",
        "    f.write(script_code)\n",
        "\n",
        "print(\"‚úî Script 04 guardado correctamente\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTpmlueIfepY",
        "outputId": "35433894-17b8-4cc2-b385-8f265a5e6a7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Script 04 guardado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.Blast import NCBIXML\n",
        "import os\n",
        "\n",
        "blast_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/blast/\"\n",
        "\n",
        "# mostrar XML disponibles\n",
        "xml_files = [f for f in os.listdir(blast_path) if f.endswith(\".xml\")]\n",
        "xml_files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNp36im9hV2f",
        "outputId": "4c250ffa-3ddd-41b1-f5c7-a4d11c2f1568"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['453_BLAST_20251121_2212.xml',\n",
              " '454_BLAST_20251121_2212.xml',\n",
              " '455_BLAST_20251121_2212.xml',\n",
              " '456_BLAST_20251121_2212.xml']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "['453_BLAST_20250121_1550.xml', '454_BLAST_20250121_1550.xml', ...]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg_n0xrmhnDc",
        "outputId": "35a7e4d7-2c25-4711-88a7-4416fa902d49"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['453_BLAST_20250121_1550.xml', '454_BLAST_20250121_1550.xml', Ellipsis]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "blast_path = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/blast/\"\n",
        "[x for x in os.listdir(blast_path) if x.endswith(\".xml\")]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM-Mb1eaipF2",
        "outputId": "a8548be3-012d-4844-bc34-274ad1fb1c02"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['453_BLAST_20251121_2212.xml',\n",
              " '454_BLAST_20251121_2212.xml',\n",
              " '455_BLAST_20251121_2212.xml',\n",
              " '456_BLAST_20251121_2212.xml']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.Blast import NCBIXML\n",
        "import os\n",
        "\n",
        "xml_file = \"453_BLAST_20251121_2212.xml\"  # ‚Üê CAMBIA\n",
        "path = f\"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/results/blast/{xml_file}\"\n",
        "\n",
        "with open(path) as result:\n",
        "    blast_record = NCBIXML.read(result)\n",
        "\n",
        "print(\"\\n=== INFORMACI√ìN DEL MEJOR HIT ===\\n\")\n",
        "\n",
        "if len(blast_record.alignments) > 0:\n",
        "    alignment = blast_record.alignments[0]\n",
        "    hsp = alignment.hsps[0]\n",
        "\n",
        "    identidad = (hsp.identities / hsp.align_length) * 100\n",
        "    cobertura = (hsp.align_length / blast_record.query_letters) * 100\n",
        "\n",
        "    print(f\"Descripci√≥n del hit: {alignment.hit_def}\")\n",
        "    print(f\"Accesion: {alignment.accession}\")\n",
        "    print(f\"Identidad: {identidad:.2f}%\")\n",
        "    print(f\"Cobertura: {cobertura:.2f}%\")\n",
        "    print(f\"E-value: {hsp.expect}\")\n",
        "    print(f\"Score: {hsp.score}\")\n",
        "else:\n",
        "    print(f\"No se encontraron hits para la secuencia en {xml_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvDPTOCpisFT",
        "outputId": "42801331-7f61-4c3b-8e61-880f533f4343"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== INFORMACI√ìN DEL MEJOR HIT ===\n",
            "\n",
            "No se encontraron hits para la secuencia en 453_BLAST_20251121_2212.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "fasta_file = \"/content/drive/MyDrive/Proyecto-Anisakidos-COX2/data/processed/453_consensus_*.fasta\"\n",
        "# Mostrar el contenido\n",
        "import glob\n",
        "files = glob.glob(fasta_file)\n",
        "files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIbgODjsjwJG",
        "outputId": "7932c409-9c0a-43b7-ab0d-663760be59cf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "record = list(SeqIO.parse(files[0], \"fasta\"))[0]\n",
        "print(record.description)\n",
        "print(record.seq)\n",
        "print(\"Longitud:\", len(record.seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "dpL6C-7mjzs8",
        "outputId": "74d48333-0054-4b17-fdf2-400cf92cba52"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1380650803.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Longitud:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}